
docker commit <cid> <new-image>   then find the difference with the base image using docker history/log

Difference between images and container lies in the top writable layer

RUN during build time while CMD on the running container on the image + RUN creates an additional layer while CMD 
writes on existing layer


################################################################################################################
gcloud command line installation (req python 2) --> download the tarball & follow doc 

APIs -> enable APIs & services for gce & k8s

gcloud components list --> gcloud components install kubectl 
gcloud config list    , gclud compute regions list , gcloud compute zones list 
gcloud config set compute/zone europe-west-1c

For GKE demo, from console with micro instance & default K8s version 

gcloud container clusters create "demo-clutser" --zone "us-central1-a" --machine-type "f1-micro"

-> connect via terminal or cloud shell 

kubectl cluster-info

Think of name spaces as partitions in harddisk. So we can partition cluster by name spaces. No 2 resources with same names in same namespace.
So partition using name space for using same names.

scp master:/etc/kubernetes/admin.conf  ~/.kube/config

kubectl get namespaces   --> by default in default ns

kubectl create namespace demo

kubectl config view --> parsing the .kube/config values 

kubectl config get-contexts

kubectl config set-context kubesys --namespace=kube-system --user=kubernetes-admin --cluster=kubernetes

kubectl config use-context kubesys  --> to switch context & namespace 

Look in the kube system namespace, kubectl -n(for name space) kube-system get pods  --> Gives you the cluster related pods
kubectl -n kube-system get pod kube-proxy-dfjj -o yaml > /tmp/mypod.yaml

watch kubectl get all -o wide   --> in one terminal 

kubectl run nginx-deploy --image nginx --replicas 2   --> deployment 

then edit possible from console since it shows yaml 

kubectl describe nginx-deploy

kubectl scale deploy nginx-deploy --replicas=4  --> 3 microinstances wont allow 4 pods

shell into container from console by kubectl -> exec == kubectl exec -it <pod> -- /bin/sh

creating service from console itself by using 'expose' 

For service , kubectl expose deployment hello-node --type=LoadBalancer --port=8080

#####################################################################################################################

Kubernetes uses etcd as its database.

The only nuance is that etcd is a distributed database – because Kubernetes is a distributed system.

etcd manages a lot of the tricky problems in running a distributed database – like race conditions and networking – and saves 
Kubernetes from worrying about it.

How does Kubernetes use etcd?
Kubernetes uses etcd as a key-value database store. It stores the configuration of the Kubernetes cluster in etcd.

It also stores the actual state of the system and the desired state of the system in etcd.

It then uses etcd’s watch functionality to monitor changes to either of these two things. If they diverge, Kubernetes makes changes to reconcile the actual state and the desired state.

A Kubernetes cluster stores all its data in etcd.

Anything you might read from a kubectl get xyz command is stored in etcd.

Any change you make via kubectl create will cause an entry in etcd to be updated.

Any node crashing or process dying causes values in etcd to be changed.

The set of processes that make up Kubernetes use etcd to store data and notify each other of changes.

#########################################################################################################################
you can see token value on master node using command:

cat /etc/kubernetes/pki/tokens.csv

The commands I used are:

kubeadm token generate
kubeadm token create <generated-token> --print-join-command --ttl=0

kubectl -n kube-system get secret clusterinfo -o yaml | grep token-map | awk '{print $2}'





