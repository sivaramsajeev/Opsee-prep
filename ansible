- name: Ensure Ansible user is present (RedHat)
  user:
   name: ansible
   comment: "ansible user created by bootstrap playbook"
   generate_ssh_key: yes
   groups: wheel
 tags:
 - bootstrap
 when: ansible_os_family=="RedHat"

- name: Ensure Ansible user is present (Debian)
  user:
   name: ansible
   comment: "ansible user created by bootstrap playbook"
   generate_ssh_key: yes
   groups: sudo
  tags:
  - bootstrap
  when: ansible_os_family=="Debian"

- name: update sudoers to ensure ansible user can sudo
  lineinfile:
    dest: /etc/sudoers
    state: present
    regexp: '^ansible'
    line: 'ansible ALL=(ALL) NOPASSWD: ALL'
  tags:
  - bootstrap
  
  ###############################################################################################################
  
  How do I skip a play in an Ansible playbook ?

This is done using the conditional execution using when

--limit /path/to/tasks.retry is for running tasks only in failed hosts 

variables may be passed via the command line -e myName=bourne  or can be added in the inventory file along with the target 
hosts or using vars in playbook itself or place it in a separate file vars.yml and execute it using -e @vars.yml or add it as 
a task  include_vars: and give the file: vars.yml or use vars_files: - vars.yml OR using set_fact:   this one is powerful 
since it can be used for generating vars dynamically  check eg below

tasks:
  - name: list contents
    command: ls /path/to/dir
    register: contents
    
  - set_fact:
    is_dir_empty: contents.stdout == ""
    
  - name: check if folder is empty
    debug: msg="folder is empty"
    when: is_dir_empty
    
  - name: installing sw in dir
    command: <install cmd>
    when: is_dir_empty
    
    



################################################################################################################

Facts

These are variables that contain information pertinent to the current host (inventory_hostname). They are only available if gathered first.

ansible_facts Contains any facts gathered or cached for the inventory_hostname Facts are normally gathered by the setup module automatically in a play, but any module can return facts.

ansible_local Contains any ‘local facts’ gathered or cached for the inventory_hostname. The keys available depend on the custom facts created. See the setup module for more details.

As an example:

ansible -i localhost, all -c local -m setup -a filter=*swap*
localhost | SUCCESS => {
    "ansible_facts": {
        "ansible_swapfree_mb": 437,
        "ansible_swaptotal_mb": 979
    },
    "changed": false
}
In your playbook your task to reset swap should then have the conditional like:

when: ansible_swap_free_mb < 500

In your case, however you  want to trigger on swap used, so you would have to compute the difference between total and free.

################################################################################################################

---
- hosts: hostnametest
  tasks:
   - name: we take swap space used (megabytes)
     shell : free -m | grep Swap | awk '{print $3}'
     register: swap_used

   - name: Turn off swap
     shell: "swapoff -a"
     when: (swap_used.stdout_lines[0] | int) > 100

   - name: Turn on swap
     shell: "swapon -a"
     when: (swap_used.stdout_lines[0] | int) > 100
     
     
   ##############################################################################################################
   
    - name: run script
   shell: runuser -l testuser -c "/tmp/test.sh"
   register: myshell_output
 - name: copy output to a local file
   lineinfile:
     dest: /thesaurus/output
     line: "{{ item }}"
     insertafter: EOF
   with_items:
    - "#####################Beginning##########################"
    - "{{ myshell_output.stdout }}"
    - "########################END#############################"
   delegate_to: localhost
   
   
    This can be done with either of the

tree or
log_plays
modules.

I would probably suggest the log_plays module in your case.


#########################################################################################################

- hosts: localhost

  tasks:
  - name: Test that my hello_world module works
    hello_world: 
    register: result

  - debug: var=result  
  
  
  Create library directory with a python file in the root of your project
hello_world.yml
[library]
   |_ hello_world.py
Add the following content to the hello_world.py


#!/usr/bin/python

from ansible.module_utils.basic import *

def main():
    module = AnsibleModule(argument_spec={})
    theReturnValue = {"hello": "world"}
    module.exit_json(changed=False, meta=theReturnValue)

if __name__ == '__main__':
    main()
    
    
    ###################################################################################################################
    
    - hosts: localhost

  tasks:
  - name: Test that my change_version module works
    version_change: 
      version_name: "Before"
      version_no:  1.1.1 
      unchanged_value: "This will pass through"
    register: result

  - debug: var=result 
  
  
  
  
  #!/usr/bin/python

from ansible.module_utils.basic import *

def main():

    fields = {
        "version_no": {"default": True, "type": "str"},
        "version_name": {"default": True, "type": "str"},
        "unchanged_value": {"default": True, "type": "str"}
    }

    module = AnsibleModule(argument_spec=fields)
    # change the name
    module.params.update({"version_name": "After"})
    # bump minor and patch version
    mylist = module.params["version_no"].split('.')
    mylist[2] = str(int(mylist[2]) + 2)
    mylist[1] = str(int(mylist[1]) + 1)
    mystr= '.'.join(mylist)
    module.params.update({"version_no": mystr})

    
    module.exit_json(changed=True, meta=module.params)


if __name__ == '__main__':
    main()
    
    #######################################################################################################################
    
    The Basics of Creating an Ansible Module
Here we will show you some of the must-follow basics steps to make a custom Ansible module.

Use common aliases across modules – name, src, dest, state
Modules should only be one file. If you need multiple files, you’re looking to make an action plugin not a module.
Modules should only return JSON; it shouldn’t be giving any errors or tracebacks.
All modules need to start with a shebang!

########################################################################################################################

Here are some basic considerations of writing Ansible modules:

Ansible will look in the library directory relative to the playbook, for example: playbooks/library/your-module
You can also specify the path to your custom modules in ansible.cfg, for example: library = /usr/share/ansible
Ansible expects modules to return JSON, for example: {'changed': false, 'failed': true, 'msg': 'could not reach the host'}
If you write your module in Python (it can be written in any language as long as it returns json) you can import Ansible helper libraries
If are using Python try to limit the libraries you are using to the standard library. If that’s not possible you need a strategy to install those libraries everywhere you will run the playbooks (preferably with your Linux distributions package manager and not pip ;) )
Good practice is to write a multi-line at the start of your module describing parameters and how to run it. This is especially important if you want to open source it.

################################################################################################################################

Here are some basic considerations of writing Ansible modules:

Ansible will look in the library directory relative to the playbook, for example: playbooks/library/your-module
You can also specify the path to your custom modules in ansible.cfg, for example: library = /usr/share/ansible
Ansible expects modules to return JSON, for example: {'changed': false, 'failed': true, 'msg': 'could not reach the host'}
If you write your module in Python (it can be written in any language as long as it returns json) you can import Ansible helper libraries
If are using Python try to limit the libraries you are using to the standard library. If that’s not possible you need a strategy to install those libraries everywhere you will run the playbooks (preferably with your Linux distributions package manager and not pip ;) )
Good practice is to write a multi-line at the start of your module describing parameters and how to run it. This is especially important if you want to open source it.
A trivial example
Let’s say we would want to write a custom module that will check if a program is running on the target host. From our playbook we will call it like this: is_running: name=consul

While this is a very trivial example (you would surely not need to write a custom module for this since it’s supported in ansible core) this will give you the needed boilerplate code needed to write a custom module, just re-implement that and focus on the real business logic you want to solve.

#!/usr/bin/python
import subprocess

DOCUMENTATION = '''
module: is_running
short_description: "Checks if a process is running on a target machine"
author:
  - your name
requirements:
  - only standard library needed
options:
  name:
    description:
      - the name of the process you want to check
      required: true
      default: null
example:  is_running: name=etcd
'''

def is_running(name):
  process = subprocess.Popen("ps -ef | grep -i " + name + " | grep -v grep", shell=True, stdout=subprocess.PIPE)
  exists = process.communicate()[0]

  if exists:
    return True
  else:
    return False

def main():
  # The AnsibleModule provides lots of common code for handling returns, parses your arguments for you, and allows you to check inputs
  module = AnsibleModule(
    argument_spec=dict(
      name=dict(required=True, type='string')
    ),
    supports_check_mode=True
  )

  # in check mode we take no action
  # since this module actually never changes system state we'll just return False
  if module.check_mode:
    module.exit_json(changed=False)

  name = module.params['name']

  if is_running(name):
    module.exit_json(changed=False)
  else:
    msg = "Program %s is not running on this host" % (name)
    module.fail_json(msg=msg)

from ansible.module_utils.basic import *
if __name__ == '__main__':
  main()
  
  ################################################################################################################
  
  subprocess.run was added in Python 3.5 as a simplification over subprocess.Popen when you just want to execute a command and wait until it finishes, but you don't want to do anything else meanwhile. For other cases, you still need to use subprocess.Popen.

The main difference is that subprocess.run executes a command and waits for it to finish, while with subprocess.Popen you can continue doing your stuff while the process finishes and then just repeatedly call subprocess.communicate yourself to pass and receive data to your process.

Note that, what subprocess.run is actually doing is invoking for you the Popen and communicate, so you don't need to make a loop to pass/receive data nor wait for the process to finish.

Check this site for the information of which parameters of subprocess.run are passed to Popen and which to communicate.



call is blocking:

call('notepad.exe')
print('hello')  # only executed when notepad is closed
Popen is non-blocking:

Popen('notepad.exe')
print('hello')  # immediately executed


The subprocess module was created with the intention of replacing several methods available in the os module, which were not considered to be very efficient. Within this module, we find the new Popen class.

The Python documentation recommends the use of Popen in advanced cases, when other methods such like subprocess.call cannot fulfill our needs. This method allows for the execution of a program as a child process. Because this is executed by the operating system as a separate process, the results are platform dependent.

The available parameters are as follows:

subprocess.Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0)

One main difference of Popen is that it is a class and not just a method. Thus, when we call subprocess.Popen, we're actually calling the constructor of the class Popen.

There are quite a few arguments in the constructor. The most important to understand is args, which contains the command for the process we want to run. It can be specified as a sequence of parameters (via an array) or as a single command string.

The second argument that is important to understand is shell, which is defaults to False. On Unix, when we need to run a command that belongs to the shell, like ls -la, we need to set shell=True.

For example, the following code will call the Unix command ls -la via a shell.

import subprocess
subprocess.Popen('ls -la', shell=True)


###########################################################################################################################################


One main difference of Popen is that it is a class and not just a method. Thus, when we call subprocess.Popen, we're actually calling the constructor of the class Popen.

There are quite a few arguments in the constructor. The most important to understand is args, which contains the command for the process we want to run. It can be specified as a sequence of parameters (via an array) or as a single command string.

The second argument that is important to understand is shell, which is defaults to False. On Unix, when we need to run a command that belongs to the shell, like ls -la, we need to set shell=True.

For example, the following code will call the Unix command ls -la via a shell.

import subprocess
subprocess.Popen('ls -la', shell=True)
The results can be seen in the output below:

$ python subprocess_popen_test.py 
total 40
drwxr-xr-x   7 scott  staff  238 Nov  9 09:13 .
drwxr-xr-x  29 scott  staff  986 Nov  9 09:08 ..
-rw-r--r--   1 scott  staff   52 Nov  9 09:13 popen2_test.py
-rw-r--r--   1 scott  staff   55 Nov  9 09:14 popen3_test.py
-rw-r--r--   1 scott  staff   53 Nov  9 09:14 popen4_test.py
-rw-r--r--   1 scott  staff   49 Nov  9 09:13 popen_test.py
-rw-r--r--   1 scott  staff   56 Nov  9 09:16 subprocess_popen_test.py
Using the following example from a Windows machine, we can see the differences of using the shell parameter more easily. Here we're opening Microsoft Excel from the shell, or as an executable program. From the shell, it is just like if we were opening Excel from a command window.

The following code will open Excel from the shell (note that we have to specify shell=True):

import subprocess
subprocess.Popen("start excel", shell=True)
However, we can get the same results by calling the Excel executable. In this case we are not using the shell, so we leave it with its default value (False); but we have to specify the full path to the executable.

import subprocess
subprocess.Popen("C:\Program Files (x86)\Microsoft Office\Office15\excel.exe")
In addition, when we instantiate the Popen class, we have access to several useful methods:

Method	Description
Popen.poll()	Checks if the child process has terminated.
Popen.wait()	Wait for the child process to terminate.
Popen.communicate()	Allows to interact with the process.
Popen.send_signal()	Sends a signal to the child process.
Popen.terminate()	Stops the child process.
Popen.kill()	Kills a child process.
The full list can be found at the subprocess documentation. The most commonly used method here is communicate.

The communicate method allows us to read data from the standard input, and it also allows us to send data to the standard output. It returns a tuple defined as (stdoutdata, stderrdata).

For example, the following code will combine the Windows dir and sort commands.

import subprocess

p1 = subprocess.Popen('dir', shell=True, stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
p2 = subprocess.Popen('sort /R', shell=True, stdin=p1.stdout)

p1.stdout.close()
out, err = p2.communicate() 
In order to combine both commands, we create two subprocesses, one for the dir command and another for the sort command. Since we want to sort in reverse order, we add /R option to the sort call.

We define the stdout of process 1 as PIPE, which allows us to use the output of process 1 as the input for process 2. Then we need to close the stdout of process 1, so it can be used as input by process 2. The communication between process is achieved via the communicate method.

Running this from a Windows command shell produces the following:

####################################################################################################################################




